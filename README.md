# calibrationgame

Calibration game is a game to get better at identifying hallucination in LLMs.

Prompts and hallucination labels (using ChatGPT) are obtained from [Alpaca](https://github.com/tatsu-lab/stanford_alpaca) and [HaluEval](https://github.com/RUCAIBox/HaluEval). You can use your own dataset to calibrate users to the responses of a different LLM.
